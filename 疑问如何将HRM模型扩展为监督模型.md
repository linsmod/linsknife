https://github.com/sapientinc/HRM (Hierarchical Reasoning Model Official Release)

U:
现在整理一份我提问的原始问题用于归档，保持问题原样输出，每行一个。

deepseek:
以下是严格按照您原始提问顺序整理的归档列表，每个问题保持原貌独立成行：

这个模型能作为语言模型训练使用吗？

从训练脚本和可视化工具代码中能看出数据格式吗？

可以把我们的任务目标分解后的ToDolist用类似这种格式表示并使用这个模型训练吗？我的设想是比如绿色格子代表子任务成功，黄色代表警告，红色代表错误，而模型的目标的达成某个比例的全绿。

你说的扩展性如何达成呢，我还想表示任务的新增，修改，展开，归并，舍弃，忽略。

传统的监督和我们这种监督有何差异。

这个hmr，能否嵌入或者附加一个变量，映射到问题嵌入或某个嵌入，用于表示步数范围的变量。或者说如果模型本身就有设计这个嵌入。这个变量在训练期间被固化为某个值，而且由于训练的缘故，自然就有一个有效范围。我希望可以在推理期间在有效范围内调整，我知道通常模型有一个温度可以调整，大概是类似的思路，但不确定是否是同样的原理。我应该是想窥探和限定或解除限定对于模型思考的迭代情况，可以做到吗。

原模型本身不是专用于语言的模型，它的循环尾部数据流是怎样的，我是想理解这一点：传统llm基于，seq到seq，使用-1偏移，hrm模型与seq到seq的数据echo的差异在哪里。

如果希望有一个可以以人类可以理解的方式观测hrm迭代过程的inspector，就类似seq到seq一样看一下它现在的状态，应该如何设计。

根据作者文章，原始hrm模型无需分层训练，在loss上h和l分别为持续下降和周期下降，所以我们可能不需要分层训练。

原生的hrm代码使用固定act的部分是怎样的？
